---
title: "Code Maktaba : Data Wrangling In R 2.0"
author: "Fridah Wanjala, M-Kopa Solar"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    theme: readable
    toc: yes
    toc_depth: '3'
    toc_float:
      collapsed: yes
---

# House keeping
## About me
  * Studied statistics
  * Currently working at M-kopa Solar
  * I used R most of the time.
  * A typical day entails SQL, drafting and implementing analysis strategies to solve business problems, R, meeting with stakeholders

## Objectives of the workshop
Data wrangling - all the activities that transform data into a format ready for analysis. 

We will cover some of these activities and hope by the end of the session:

  *	Understand data control structures and how to implement them in R
  *	Learn how to handle repetitive tasks using loops and the apply family of functions.
  
In the last session we learnt ;

  * Data structures in R e.g vectors, lists, dataframes.
  * How to subset vectors and lists using indices and character names
  * We also learnt how to subset data frames using the `select` and `filter` functions and their variations from the `dplyr` package.
  * We also learnt how to create an R workfows using RStudio projects
  
### House keeping
Before we begin:
  * Create a folder - give it a name of your choice. Within it create a subfolder : `data`
  * Download two datasets and scripts from the link provided on the board.
  * Place the data in the data folder and scripts in the main folder.
  * Creat an R project. This will be saved with a .Rproj extension. Alaways use R projects to manage your workflow.

This workshop assumes that
  * You basic knowldge of R
  * Navigate RStudio (both R and Rstudio)
  * Understand the different data structures
  * Understand the different data types in R, i.e, string/character, numeric, logical, factor/categorical.
  * You can import data into R
  * You can create a new script or open the RMarkdown files you have downloaded
  * We are now set, any questions?

## Important things to note.

* Feel free to ask questions during the session. Raise your hand and one of the team members will come over to assist.
* At the end of each segment, there will be an exercise where you will be given atleast 10 minutes to work on it.

# Introduction
A business problem that requires a data solution has to under a series of stages.
* Understand the problem.
* Define the goal of the project.
* Collect relevant data.
*	**Prepare the data for analysis.**
*	Analyze the cleaned data.
* Communicate the findings


First, we will load the packages required packages. 
```{r setup, include=FALSE}
#-----------------------------------------------------
# 0. Set the working environment
#-----------------------------------------------------
# Install packages
# install.packages("dplyr", repos='http://cran.us.r-project.org', )
# install.packages("purrr", repos='http://cran.us.r-project.org')
# install.packages("readxl", repos='http://cran.us.r-project.org')

# Load packages
library("dplyr")
library("purrr")
require("readxl")

```

## Import the dataset
Below is a glimpse of the data we will use in today's session. It was collected from some insurance company's marketing campaign. The goal was to understand how different customers react to different marketing strategies.

The pipe operator (`%>%`) allows you to structure sequences of operations such that it takes the value on the left and forwards it to the expression/function on the right.

```{r}
# Import the dataset
bank_df <- read_excel("data/Marketing-Customer-Value-Analysis-Merged.xlsx")

# Structure of the dataset
bank_df %>% glimpse()
str(bank_df)

# This is the same as
glimpse(bank_df)

```

## Recap
### Subsetting data frame columns.
Here the goal is to keep or drop specific columns. We will use the `select` function from dplyr.

```{r}
# Selecting one column
location_code1 <- bank_df %>% select(`Location Code`)
location_code2 <- bank_df %>% pull(`Location Code`)

# Selecting several columns
output2 <- bank_df %>% select(`Location Code`, `Total Claim Amount`)

```

### Subsetting rows
Here, the goal is to keep/drop rows that are of interest e.g Keep non-missing rows.

We will use the `filter` function from the `dplyr` package. 

```{r}
# Numeric columns : Relational operators : >, <=, != etc
out <- bank_df %>% filter(Income > 0)

# Character columns
out <- bank_df %>%
  filter(`Vehicle Class` == "Sports Car")

# More than one item
out <- bank_df %>%
  filter(`Vehicle Class` %in% c("Two-Door Car", "Four-Door Car"))

```

Let's jump into today's session.

# First session : Conditional statements
These are statements that control the flow of the analysis. That is, they determine if a certain condition is met or not, then perform a set of analysis depending on whether a condition is met or not.

Below are examples of common conditional statements.

* `if() {}` : Executes a set of statement(s) when condition is met
* `if() {} else {}` : Executes statement 1 if a condition met; if not executes statement 2
* `ifelse()` : Execute statement 1 if condition met; if not execute statement 2
* `which()` : Find elements in an object that meet condition

Let's try out some examples to showcase their differences. 

## The `if {} and if() {} else {}` statement
Suppose you you would like to perform some operation only when some condition is met, say, 

1. If a number is greater than or equal 10, compute the square root
2. Else print out a message [The number is less than 10, no computation]

```{r}
# Define a variable x
x <- c(7,9)

# Apply your protocol
if(x > 10){
  sqrt(x)
} else if (x = 10){
  print(x)
} else {
  print("The number is less than 10, no computation")
}

```

Note :  This should only be used on a vector with one element. Demonstrate.

Use case : package installation.

```{r}
# Vector of required packages
pkgs <- c("tidyverse", "glue", "tools", "lubridate", 
          "readxl", "DBI", "aml")

# Installed packages
installed <- installed.packages()[, 1]

# Create vector of missing packages
miss_pkgs <- pkgs[!pkgs %in% installed] 

# Install the missing packages
if(length(miss_pkgs)>0){
  install.packages(miss_pkgs, dependencies = TRUE)
}

```

This makes your script robust and easy to run on another computer that does not have these dependencies installed.

## The ifelse stament
Structure of an `ifelse` statements

```
ifelse(Condition, yes, no)
```
Note : Good news -it can be applied on vectors. This means we can use this function to create new variables and add to a dataframe.

```{r}
# Suppose I have a vector of numbers
numbers <- c(-2,-3, -4, 2, 6, 9)

# Replace negatives with 0
ifelse(numbers < 0, 0, numbers)

```

Example :  Let's create a categorical variable from a continous variable. Create two categories from this variable : `Number of Open Complaints`, that is `No complaints` and `At least one complaint`. Let's call this new variable : `Complaints_category` 

Method 1 : Using Base R
```{r}
# Create the variable
bank_df$Complaints_category <- ifelse(bank_df$`Number of Open Complaints` == 0, "No complaints", "At least one complaint")

# Distribution of the original and new variable
table(bank_df$`Number of Open Complaints`)
table(bank_df$Complaints_category)

```


Method 2 :  Using dplyr's `mutate` verb
```{r}
# Functions within dplyr package
help(package = "dplyr")

# Create the variable
bank_df <- bank_df %>%
  mutate(Complaints_category2 = ifelse(`Number of Open Complaints` == 0, "No complaints", "At least one complaint"))

# Distribution of the original and new variable
table(bank_df$`Number of Open Complaints`)
table(bank_df$Complaints_category2)
```

## The which statement
The `which(condition)` retuns the row number of the object that meets a condition.

```{r}
# Vector of say, weight of children
weight <- c(5, 12, 14, 15, 17, 10, 11, NA)

# Find indices where weight > 13
which(is.na(weight))

# Subsetting - Extract weights greater than 13
weight[which(weight > 13)]

# Variants of the which function
weight[which.max(weight)]
weight[which.min(weight)]

```

Mostly used when performing vector operations.

## Exercise
Using the marketing dataset do the following. You have 10 minutes to try this out.
```
Create a new variable `Income_category` using the following protocol:
Income = 0 "No Income"
Income = between 1 and 50,000 "1 to 50000"
Income > 50000 "> 50000"
HINT :  Use nested `ifelse`
```
```{r}
bank_df <- bank_df %>%
  mutate(Income_category = ifelse(Income == 0, "No income",
                                  ifelse(between(Income, 1, 50000),
                                         "1 to 50000", ">50000")))

table(bank_df$Income_category)
```


# Third section : Loops and the apply family
## Loops
A loop provides a framework for performing repeated operations without having to change the parameters of the statement. 

Examples of repeated operations.
1. Reading in a bunch of csv/excel or any other type of file.
2. You want to call a function but you have lots of inputs. A function is a set of instructions to carry out a specific task. It has an input and output.

The number of times a loop runs is determined by start and stop conditions. Below is the structure of a loop.

```
for(i in 1:4){
  Statements()
}
```

Where:
i : is the counter/placeholder
1 : start
4 : stop

```{r}
for(i in 1:9){
  print(i)
}
```


Example : Suppose we want to import data from an a Excel workbook with several sheets such that you can only import one sheet at a time.

Step 1 : Pick the package and function you will use.
```
Package : readxl
Function : read_excel
```
Step 2: Create vector with the names of worksheets in the work book. This is what we will loop/iterate over.

```{r}
## Vector of sheets 
(data_sheets <- excel_sheets(path = "data/Several_datasets.xlsx"))

```

Step 3 :  Test the import function by importing data from one worksheet. This is the code that wll be run in every iteration.

```{r}
first_df <- read_excel(path = "data/Several_datasets.xlsx", sheet = "starwars")
```

Step 4: Create an empty list that will be used to store the imported datasets

```{r}
datasets <- list()
```

Step 5: Write the loop. There are different ways to create the looping index: 
(i) Could be numueric index

```{r}
# Define space for the output
datasets_index <- list()

# Import from different sheets
for(i in 1:length(data_sheets)){
  print(i)
  datasets_index[[i]] <- read_excel(path = "data/Several_datasets.xlsx", sheet = data_sheets[i])
}

# Extract the datasets from the list - one needs to remmember the order of the sheets

ChickWeight <- datasets_index[[1]]

```

(ii) Character index

```{r}
datasets_chr <- list()

for(sht in data_sheets){
  print(sht)
  datasets_chr[[sht]] <- read_excel(path = "data/Several_datasets.xlsx", sheet = sht)
}

ChickWeight <- datasets_chr[["ChickWeight"]]
```

*Exercise*
Write a loop that calculates the mean, median and standard deviation of the following numeric variables (Income, Total Claim Amount, Customer Lifetime Value) and saves the 3 outputs in a list. Hint .  Use the `pull` function from the `dplyr` package to extract the variables.

```{r}
cols <- c("Income", "Total Claim Amount", "Customer Lifetime Value")
outp_lst <- list()

for(i in 1:length(cols)){
  print(i)
  data <- bank_df %>% pull(cols[i])
  means <- mean(data)
  med <- median(data)
  sds <- sd(data)
  temp <- c("mean"= means, "median" = med, "sd" = sds)
  
  outp_lst[[i]] <- temp
}

outp_lst

```

## Apply family of functions
Instead of using loops, one can use some the `apply()` family of functions. These are functions that can take in an input vector, array or matrix and apply a function with one or several arguments.

There are several apply functions such as apply, lapply, sapply, mapply etc, but we will only talk about the two most common. They are all R base functions.

Don't worry if you don't understand them today. It took me some practice to actually master them. You will get there if you do the same.

* `apply()` - this is the godfather and takes in matrices/dataframes as input. It is structured as `apply(x, margin, FUN)`. MARGIN can be 1 (rows) or 2 (columns)

For example,to calculate the means of all the column of the `mtcars` dataset (this is an inbuilt R dataset)

```{r}

# First we load the data
data(mtcars)

# Calculate the mean
apply(X = mtcars, MARGIN = 2, FUN = mean)

mtcars$totals <- apply(X = mtcars, MARGIN = 1, FUN = sum)

```

Exercise:
Using the `apply` function, calculate the sum total of each row of the `mtcars` dataset. Add this new variable to the dataset.

* `lapply()` - This applies a function over a list or vector, then outputs a list. Using the previous example of importing datasets, we can use lapply as an alternative to the loop. It is strucutred as follows: `lapply(X, FUN)`. Works well with one-argument functions.

```{r}
# We need a function that we will pass over to the lapply function : Recap - function
import_data <- function(x){
  data <- read_excel(path = "data/Several_datasets.xlsx", sheet = x)
  return(data)
}

# We will pass a vector of data sheet names over the read_excel function 
lapply_lst <- lapply(X = data_sheets, FUN = import_data)

```


## The purrr package map functions
The map functions are also alternative toloops and iteratively apply a list or a vector to a function. The functions are:
* `map(x, f)` :  applies a function to each element of a list or vector. This requires a one-argument function. Using our previous example, we can use the map function to iterate over the sheets and importthe data.

```{r}
# Methdd 1:
map_lst1 = map(.x = data_sheets, 
               .f = import_data)

# Method 2 : Uisng the pipe operatoe
map_lst2 <- data_sheets %>%
  map(~ import_data(.))
  
```

* map2 and pmap :  Same as map but require a function with 2 and more arguments. We will not go into the details now since it will be discussed in  future session.

## Exercise.
Below is a function that takes in a variable name and ouputs its data type. Use `lapply` or `map` to apply function to all the column names in the marketing dataset. First create in function within your R workspace.

```
classes <- function(x){
  return(typeof(bank_df %>% pull(x)))
}
```

# Closing remarks // Remarks

* Hope you have enjoyed and learnt a lot.
* R requires practice. Take a problem and try to solve it with R. Publish it on rpubs,
  github pages, or a blog of your choice.
* Offer to train at meetups.
* Follow data science groups and individuals on LinkedIn, Twitter e.g Hardley Wickham
* Read data blogs - google blog, R weekly
* Online courses - Coursera, DataQuest


# Resources

1. [Variants of the filter verb](https://dplyr.tidyverse.org/reference/filter_all.html)
2. [Susan Baert's blog](https://suzanbaert.netlify.com/2018/01/dplyr-tutorial-1/)